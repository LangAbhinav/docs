{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyML3v+04lClCsIh4Hhhe11W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LangAbhinav/docs/blob/main/songnew1ofnew.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7Tr9mIao-Q7",
        "outputId": "4d334fac-e7fa-4b4c-938d-907a5e9daeac"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "file_path = '/content/drive/MyDrive/dataset/song/song.zip'\n",
        "with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n"
      ],
      "metadata": {
        "id": "hwXb31sZpbqB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import string\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "V3kOhpHTr0ic"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "def tokenize_new(new, num_words=-1):\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(new)\n",
        "  return tokenizer\n",
        "\n",
        "def create_lyrics_new(df, text):\n",
        "  # Remove all other punctuation\n",
        "  df[text] = df[text].str.replace('[{}]'.format(string.punctuation), '')\n",
        "  # Make it lowercase\n",
        "  df[text] = df[text].str.lower()\n",
        "  # Make it one long string to split by line\n",
        "  lyrics = df[text].str.cat()\n",
        "  new = lyrics.split('\\n')\n",
        "  # Remove any trailing whitespace\n",
        "  for l in range(len(new)):\n",
        "    new[l] = new[l].rstrip()\n",
        "  # Remove any empty lines\n",
        "  new = [l for l in new if l != '']\n",
        "\n",
        "  return new\n"
      ],
      "metadata": {
        "id": "AI6Yiw4Lp32p"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(file_path, encoding=\"ISO-8859-1\", dtype=str)[:10]\n",
        "new = create_lyrics_new(df, 'lyric')\n",
        "# Tokenize the corpus\n",
        "tokenizer = tokenize_new(new)\n",
        "\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQP2MA8drGsN",
        "outputId": "ddf595f0-3f4f-4885-a162-3aeb017af11c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a': 1, 'said': 2, 'the': 3, 'my': 4, 'to': 5, 'that': 6, 'summer': 7, 'you': 8, 'think': 9, 'he': 10, 'way': 11, 'blue': 12, 'eyes': 13, 'shinedput': 14, 'those': 15, 'georgia': 16, 'stars': 17, 'shame': 18, 'nighti': 19, 'thats': 20, 'liejust': 21, 'boy': 22, 'in': 23, 'chevy': 24, 'truckthat': 25, 'had': 26, 'tendency': 27, 'of': 28, 'gettin': 29, 'stuckon': 30, 'backroads': 31, 'at': 32, 'nightand': 33, 'i': 34, 'was': 35, 'right': 36, 'there': 37, 'beside': 38, 'him': 39, 'all': 40, 'longand': 41, 'then': 42, 'time': 43, 'we': 44, 'woke': 45, 'up': 46, 'find': 47, 'gonebut': 48, 'when': 49, 'tim': 50, 'mcgrawi': 51, 'hope': 52, 'favorite': 53, 'song': 54}\n",
            "55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-f5af19287d58>:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df[text] = df[text].str.replace('[{}]'.format(string.punctuation), '')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = []\n",
        "for line in new:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tsequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences for equal input length\n",
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
        "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
        "# One-hot encode the labels\n",
        "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "metadata": {
        "id": "5h_sfzFWsyd8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(50)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#history = model.fit(input_sequences, one_hot_labels, epochs=500, verbose=1)\n",
        "history = model.fit(input_sequences, one_hot_labels, epochs=200, batch_size=2, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8Ccui7asI2k",
        "outputId": "c6f00b2b-ea9d-4465-bc6f-95fe31cd6f4c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "32/32 [==============================] - 7s 106ms/step - loss: 4.0233 - accuracy: 0.0000e+00\n",
            "Epoch 2/200\n",
            "32/32 [==============================] - 1s 33ms/step - loss: 3.9873 - accuracy: 0.0625\n",
            "Epoch 3/200\n",
            "32/32 [==============================] - 1s 31ms/step - loss: 3.9355 - accuracy: 0.0781\n",
            "Epoch 4/200\n",
            "32/32 [==============================] - 1s 31ms/step - loss: 3.7533 - accuracy: 0.1094\n",
            "Epoch 5/200\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 3.4562 - accuracy: 0.1094\n",
            "Epoch 6/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 3.2244 - accuracy: 0.0938\n",
            "Epoch 7/200\n",
            "32/32 [==============================] - 1s 23ms/step - loss: 3.0138 - accuracy: 0.1406\n",
            "Epoch 8/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.8444 - accuracy: 0.1562\n",
            "Epoch 9/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 2.6843 - accuracy: 0.1250\n",
            "Epoch 10/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 2.5980 - accuracy: 0.1562\n",
            "Epoch 11/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 2.4452 - accuracy: 0.1562\n",
            "Epoch 12/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 2.3342 - accuracy: 0.1875\n",
            "Epoch 13/200\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 2.2406 - accuracy: 0.1875\n",
            "Epoch 14/200\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 2.1599 - accuracy: 0.3281\n",
            "Epoch 15/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 2.1021 - accuracy: 0.1875\n",
            "Epoch 16/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.0437 - accuracy: 0.3125\n",
            "Epoch 17/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.9774 - accuracy: 0.2656\n",
            "Epoch 18/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.9053 - accuracy: 0.2969\n",
            "Epoch 19/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.8590 - accuracy: 0.3281\n",
            "Epoch 20/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.7757 - accuracy: 0.4844\n",
            "Epoch 21/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.7315 - accuracy: 0.4375\n",
            "Epoch 22/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.6957 - accuracy: 0.4219\n",
            "Epoch 23/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.6423 - accuracy: 0.5000\n",
            "Epoch 24/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.6088 - accuracy: 0.5312\n",
            "Epoch 25/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.5505 - accuracy: 0.6250\n",
            "Epoch 26/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.5012 - accuracy: 0.6250\n",
            "Epoch 27/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4652 - accuracy: 0.6250\n",
            "Epoch 28/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4275 - accuracy: 0.7031\n",
            "Epoch 29/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.3713 - accuracy: 0.7344\n",
            "Epoch 30/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.3282 - accuracy: 0.7812\n",
            "Epoch 31/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.2799 - accuracy: 0.7188\n",
            "Epoch 32/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.2363 - accuracy: 0.7969\n",
            "Epoch 33/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.2075 - accuracy: 0.8438\n",
            "Epoch 34/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1648 - accuracy: 0.8281\n",
            "Epoch 35/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1221 - accuracy: 0.8750\n",
            "Epoch 36/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0898 - accuracy: 0.8594\n",
            "Epoch 37/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0530 - accuracy: 0.8750\n",
            "Epoch 38/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0113 - accuracy: 0.9375\n",
            "Epoch 39/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.9695 - accuracy: 0.9375\n",
            "Epoch 40/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.9473 - accuracy: 0.8906\n",
            "Epoch 41/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.9107 - accuracy: 0.9062\n",
            "Epoch 42/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.8741 - accuracy: 0.9375\n",
            "Epoch 43/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.8292 - accuracy: 0.9688\n",
            "Epoch 44/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.8063 - accuracy: 0.9688\n",
            "Epoch 45/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.7800 - accuracy: 0.9531\n",
            "Epoch 46/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.7507 - accuracy: 0.9688\n",
            "Epoch 47/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.7276 - accuracy: 0.9688\n",
            "Epoch 48/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6889 - accuracy: 1.0000\n",
            "Epoch 49/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6499 - accuracy: 0.9688\n",
            "Epoch 50/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6321 - accuracy: 1.0000\n",
            "Epoch 51/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5964 - accuracy: 1.0000\n",
            "Epoch 52/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5688 - accuracy: 0.9844\n",
            "Epoch 53/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5451 - accuracy: 1.0000\n",
            "Epoch 54/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5166 - accuracy: 1.0000\n",
            "Epoch 55/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5095 - accuracy: 1.0000\n",
            "Epoch 56/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.4799 - accuracy: 1.0000\n",
            "Epoch 57/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.4550 - accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.4408 - accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.4126 - accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.3901 - accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.3786 - accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.3715 - accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.3568 - accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.3324 - accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3131 - accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.2985 - accuracy: 1.0000\n",
            "Epoch 67/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.2806 - accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.2661 - accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.2530 - accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.2489 - accuracy: 1.0000\n",
            "Epoch 71/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.2345 - accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.2228 - accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.2154 - accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.2053 - accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1961 - accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1871 - accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1776 - accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1699 - accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1636 - accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1570 - accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1508 - accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1433 - accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1388 - accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1327 - accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1285 - accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1239 - accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1186 - accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1138 - accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1221 - accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1240 - accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1242 - accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1159 - accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1029 - accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1017 - accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1103 - accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1037 - accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0999 - accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0928 - accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0876 - accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0842 - accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0802 - accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0770 - accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0740 - accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0725 - accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0702 - accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0681 - accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0659 - accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0636 - accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0612 - accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0587 - accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0573 - accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0553 - accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0538 - accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0531 - accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0508 - accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0504 - accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0523 - accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0529 - accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0489 - accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0468 - accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0447 - accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0430 - accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0417 - accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0407 - accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0397 - accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0384 - accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0370 - accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0361 - accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0353 - accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0341 - accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0333 - accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0329 - accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0317 - accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0308 - accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0304 - accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0295 - accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0290 - accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0277 - accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0272 - accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0266 - accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0259 - accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0256 - accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0247 - accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0242 - accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0235 - accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0230 - accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0225 - accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0220 - accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0215 - accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0209 - accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0205 - accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0205 - accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0200 - accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0195 - accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0190 - accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0185 - accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0181 - accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0177 - accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0172 - accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0168 - accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0166 - accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0162 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0157 - accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0154 - accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0152 - accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0148 - accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0145 - accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0143 - accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0140 - accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0136 - accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0133 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0130 - accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0128 - accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0129 - accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0127 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0123 - accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0120 - accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0116 - accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0114 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0111 - accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0109 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0106 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0105 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0102 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0099 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0096 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0095 - accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0092 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0090 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0087 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0085 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0084 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0082 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0079 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0078 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0076 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0073 - accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0071 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "_D8klHt3tVO5",
        "outputId": "a372a4e9-f526-4dec-91dc-6c834a8d0029"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the training data\n",
        "train_loss, train_accuracy = model.evaluate(input_sequences, one_hot_labels, verbose=1)\n",
        "\n",
        "# Print the training accuracy\n",
        "print(\"Training Accuracy:\", train_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu2YBL64hv3q",
        "outputId": "174820ac-6196-4951-ba9e-c201f1a38711"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 11ms/step - loss: 0.0068 - accuracy: 1.0000\n",
            "Training Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"i am in love baby\"\n",
        "next_words = 100\n",
        "\n",
        "generated_text = seed_text\n",
        "for _ in range(next_words):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "    output_word = \"\"\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted:\n",
        "            output_word = word\n",
        "            break\n",
        "    seed_text += \" \" + output_word\n",
        "    generated_text += \" \" + output_word\n",
        "\n",
        "# Print the generated text\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBQD22WgdvwB",
        "outputId": "3bb98233-5ad3-435a-e661-10c73cecf873"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 588ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "i am in love baby said the way my blue eyes shinedput those georgia stars to shame that nighti said thats a liejust a boy in a chevy truckthat had a tendency of gettin stuckon backroads at nightand i was right there beside him all summer longand then the time we woke up to find that summer gonebut when you think tim mcgrawi hope you think my favorite song favorite song song song song song song song song song summer gonebut when you think tim mcgrawi summer gonebut when you think my think my favorite hope you favorite song song song song song favorite song\n"
          ]
        }
      ]
    }
  ]
}